{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 10:19:21.980933: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-20 10:19:22.034528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-20 10:19:22.034550: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-20 10:19:26.351334: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-20 10:19:26.351369: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-20 10:19:26.351396: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jesusarguelles1): /proc/driver/nvidia/version does not exist\n",
      "2022-10-20 10:19:26.352121: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:An attribute in the restored object could not be found in the checkpoint. Object: (root).layer_with_weights-0.token_counts, attribute: ['table']\n",
      "WARNING:tensorflow:An attribute in the restored object could not be found in the checkpoint. Object: (root).layer_with_weights-1.token_counts, attribute: ['table']\n",
      "WARNING:tensorflow:An attribute in the restored object could not be found in the checkpoint. Object: (root).layer_with_weights-2.token_counts, attribute: ['table']\n",
      "WARNING:tensorflow:An attribute in the restored object could not be found in the checkpoint. Object: (root).layer_with_weights-3.token_counts, attribute: ['table']\n",
      "WARNING:tensorflow:An attribute in the restored object could not be found in the checkpoint. Object: (root).layer_with_weights-4.token_counts, attribute: ['table']\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " source (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " medium (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " channelGrouping (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " deviceCategory (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " country (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " latest_ecommerce_progress (Inp  [(None, 1)]         0           []                               \n",
      " utLayer)                                                                                         \n",
      "                                                                                                  \n",
      " bounces (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " time_on_site (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " pageviews (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " string_lookup (StringLookup)   (None, 1)            0           ['source[0][0]']                 \n",
      "                                                                                                  \n",
      " string_lookup_1 (StringLookup)  (None, 1)           0           ['medium[0][0]']                 \n",
      "                                                                                                  \n",
      " string_lookup_2 (StringLookup)  (None, 1)           0           ['channelGrouping[0][0]']        \n",
      "                                                                                                  \n",
      " string_lookup_3 (StringLookup)  (None, 1)           0           ['deviceCategory[0][0]']         \n",
      "                                                                                                  \n",
      " string_lookup_4 (StringLookup)  (None, 1)           0           ['country[0][0]']                \n",
      "                                                                                                  \n",
      " normalization (Normalization)  (None, 1)            3           ['latest_ecommerce_progress[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " normalization_1 (Normalization  (None, 1)           3           ['bounces[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_2 (Normalization  (None, 1)           3           ['time_on_site[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_3 (Normalization  (None, 1)           3           ['pageviews[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " category_encoding (CategoryEnc  (None, 5)           0           ['string_lookup[0][0]']          \n",
      " oding)                                                                                           \n",
      "                                                                                                  \n",
      " category_encoding_1 (CategoryE  (None, 5)           0           ['string_lookup_1[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_2 (CategoryE  (None, 5)           0           ['string_lookup_2[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_3 (CategoryE  (None, 4)           0           ['string_lookup_3[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_4 (CategoryE  (None, 5)           0           ['string_lookup_4[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 28)           0           ['normalization[0][0]',          \n",
      "                                                                  'normalization_1[0][0]',        \n",
      "                                                                  'normalization_2[0][0]',        \n",
      "                                                                  'normalization_3[0][0]',        \n",
      "                                                                  'category_encoding[0][0]',      \n",
      "                                                                  'category_encoding_1[0][0]',    \n",
      "                                                                  'category_encoding_2[0][0]',    \n",
      "                                                                  'category_encoding_3[0][0]',    \n",
      "                                                                  'category_encoding_4[0][0]']    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           928         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 32)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            33          ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 973\n",
      "Trainable params: 961\n",
      "Non-trainable params: 12\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "reloaded_model = tf.keras.models.load_model(\"gs://vtx-models/purchase/model\")\n",
    "reloaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = { \n",
    "    \"instances\": \n",
    "    [\n",
    "        {\n",
    "            'latest_ecommerce_progress': 0,\n",
    "            'bounces': 0,\n",
    "            'time_on_site': 103,\n",
    "            'pageviews': 3,\n",
    "            'source': 'youtube.com',\n",
    "            'medium': 'referral',\n",
    "            'channelGrouping': 'Social',\n",
    "            'deviceCategory': 'desktop',\n",
    "            'country': 'Vietnam',\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': [{'latest_ecommerce_progress': 0,\n",
       "   'bounces': 0,\n",
       "   'time_on_site': 103,\n",
       "   'pageviews': 3,\n",
       "   'source': 'youtube.com',\n",
       "   'medium': 'referral',\n",
       "   'channelGrouping': 'Social',\n",
       "   'deviceCategory': 'desktop',\n",
       "   'country': 'Vietnam'}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ \n",
    "    \"instances\": \n",
    "    [\n",
    "        {\n",
    "            \"latest_ecommerce_progress\": 0,\n",
    "            \"bounces\": 0,\n",
    "            \"time_on_site\": 103,\n",
    "            \"pageviews\": 3,\n",
    "            \"source\": \"youtube.com\",\n",
    "            \"medium\": \"referral\",\n",
    "            \"channelGrouping\": \"Social\",\n",
    "            \"deviceCategory\": \"desktop\",\n",
    "            \"country\": \"Vietnam\",\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "tf.Tensor([4.4568943e-10], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "instances = x['instances']\n",
    "for i in instances:\n",
    "    input_dict = {name: tf.convert_to_tensor([value]) for name, value in i.items()}\n",
    "    predictions = reloaded_model.predict(input_dict)\n",
    "    prob = tf.nn.sigmoid(predictions[0])\n",
    "    print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jchavezar-demo'\n",
    "NUM_NEURONS = 32\n",
    "L_RATE = 0.001\n",
    "EPOCHS = 10\n",
    "TRAIN_START_DATE = \"20160801\"\n",
    "TRAIN_END_DATE = \"20170430\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src import Estimator\n",
    "\n",
    "VertexTF = Estimator.VertexTF(\n",
    "    project_id=PROJECT_ID,\n",
    "    epochs=10\n",
    ")\n",
    "train, val, test = VertexTF.query(start_date=TRAIN_START_DATE, end_date=TRAIN_END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>will_buy_on_return_visit</th>\n",
       "      <th>latest_ecommerce_progress</th>\n",
       "      <th>bounces</th>\n",
       "      <th>time_on_site</th>\n",
       "      <th>pageviews</th>\n",
       "      <th>source</th>\n",
       "      <th>medium</th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>deviceCategory</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197864</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>youtube.com</td>\n",
       "      <td>referral</td>\n",
       "      <td>Social</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Vietnam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464234</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youtube.com</td>\n",
       "      <td>referral</td>\n",
       "      <td>Social</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507839</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>google</td>\n",
       "      <td>organic</td>\n",
       "      <td>Organic Search</td>\n",
       "      <td>desktop</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>7</td>\n",
       "      <td>dfa</td>\n",
       "      <td>cpm</td>\n",
       "      <td>Display</td>\n",
       "      <td>desktop</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94915</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>google</td>\n",
       "      <td>organic</td>\n",
       "      <td>Organic Search</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506481</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>706</td>\n",
       "      <td>24</td>\n",
       "      <td>googleux.perksplus.com</td>\n",
       "      <td>referral</td>\n",
       "      <td>Referral</td>\n",
       "      <td>desktop</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123264</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>youtube.com</td>\n",
       "      <td>referral</td>\n",
       "      <td>Social</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Tunisia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76301</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>439</td>\n",
       "      <td>17</td>\n",
       "      <td>google</td>\n",
       "      <td>organic</td>\n",
       "      <td>Organic Search</td>\n",
       "      <td>desktop</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531375</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youtube.com</td>\n",
       "      <td>referral</td>\n",
       "      <td>Social</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>google.com</td>\n",
       "      <td>referral</td>\n",
       "      <td>Referral</td>\n",
       "      <td>mobile</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458400 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        will_buy_on_return_visit  latest_ecommerce_progress  bounces  \\\n",
       "197864                         0                          0        0   \n",
       "464234                         0                          0        1   \n",
       "507839                         0                          2        0   \n",
       "146195                         0                          0        0   \n",
       "94915                          0                          0        1   \n",
       "...                          ...                        ...      ...   \n",
       "506481                         0                          2        0   \n",
       "123264                         0                          0        0   \n",
       "76301                          0                          2        0   \n",
       "531375                         0                          0        1   \n",
       "37818                          0                          0        1   \n",
       "\n",
       "        time_on_site  pageviews                  source    medium  \\\n",
       "197864           103          3             youtube.com  referral   \n",
       "464234             0          1             youtube.com  referral   \n",
       "507839            22          3                  google   organic   \n",
       "146195           184          7                     dfa       cpm   \n",
       "94915              0          1                  google   organic   \n",
       "...              ...        ...                     ...       ...   \n",
       "506481           706         24  googleux.perksplus.com  referral   \n",
       "123264            52          2             youtube.com  referral   \n",
       "76301            439         17                  google   organic   \n",
       "531375             0          1             youtube.com  referral   \n",
       "37818              0          1              google.com  referral   \n",
       "\n",
       "       channelGrouping deviceCategory        country  \n",
       "197864          Social        desktop        Vietnam  \n",
       "464234          Social        desktop           Peru  \n",
       "507839  Organic Search        desktop  United States  \n",
       "146195         Display        desktop  United States  \n",
       "94915   Organic Search        desktop          Italy  \n",
       "...                ...            ...            ...  \n",
       "506481        Referral        desktop  United States  \n",
       "123264          Social        desktop        Tunisia  \n",
       "76301   Organic Search        desktop  United States  \n",
       "531375          Social        desktop         Turkey  \n",
       "37818         Referral         mobile  United States  \n",
       "\n",
       "[458400 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 164ms/step\n",
      "This particular pet had a 0.0 percent probability of getting adopted.\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    'latest_ecommerce_progress': 0,\n",
    "    'bounces': 0,\n",
    "    'time_on_site': 103,\n",
    "    'pageviews': 3,\n",
    "    'source': 'youtube.com',\n",
    "    'medium': 'referral',\n",
    "    'channelGrouping': 'Social',\n",
    "    'deviceCategory': 'desktop',\n",
    "    'country': 'Vietnam',\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = reloaded_model.predict(input_dict)\n",
    "prob = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This particular pet had a %.1f percent probability \"\n",
    "    \"of getting adopted.\" % (100 * prob)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jesusarguelles/code/vertex-gpu/pipe_notebook/draft/draf.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jesusarguelles/code/vertex-gpu/pipe_notebook/draft/draf.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m reloaded_model\u001b[39m.\u001b[39;49mpredict(train\u001b[39m.\u001b[39;49miloc[:\u001b[39m1\u001b[39;49m,:]\u001b[39m.\u001b[39;49mto_numpy())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "reloaded_model.predict(train.iloc[:1,:].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
