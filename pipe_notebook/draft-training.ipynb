{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 14:44:56.933764: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-08-09 14:44:56.952935: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-09 14:44:56.952951: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jesusarguelles/.keras/datasets/auto-mpg.data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
    "dataset_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "dataset = pd.read_csv(dataset_path, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      sep=\" \", skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "0    18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1    15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2    18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3    16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4    17.0          8         302.0       140.0  3449.0          10.5   \n",
       "..    ...        ...           ...         ...     ...           ...   \n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     Model Year  Origin  \n",
       "0            70       1  \n",
       "1            70       1  \n",
       "2            70       1  \n",
       "3            70       1  \n",
       "4            70       1  \n",
       "..          ...     ...  \n",
       "393          82       1  \n",
       "394          82       2  \n",
       "395          82       1  \n",
       "396          82       1  \n",
       "397          82       1  \n",
       "\n",
       "[398 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr custom_draft\n",
    "!mkdir custom_draft\n",
    "!touch custom_draft/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting custom_draft/ctx.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile custom_draft/ctx.py\n",
    "\n",
    "MODEL_URI='gs://vtx-models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting custom_draft/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile custom_draft/preprocess.py\n",
    "\n",
    "from custom_draft import ctx\n",
    "\n",
    "## Data Cleaning and Normalizating, exporting statistics.\n",
    "\n",
    "def train_pre_process(dataset):\n",
    "    import pandas as pd\n",
    "\n",
    "    dataset = dataset.dropna()\n",
    "    dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "    dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\n",
    "    \n",
    "    train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "    test_dataset = dataset.drop(train_dataset.index)\n",
    "    \n",
    "    train_stats = train_dataset.describe()\n",
    "    train_stats.pop('MPG')\n",
    "    train_stats = train_stats.transpose()\n",
    "    train_stats.to_csv(f'{ctx.MODEL_URI}/mpg/stats.csv')\n",
    "    train_stats.to_csv('stats_2.csv')\n",
    "    train_labels = train_dataset.pop('MPG')\n",
    "    test_labels = test_dataset.pop('MPG')\n",
    "    \n",
    "    def norm(x):\n",
    "        return (x - train_stats['mean'])/train_stats['std']\n",
    "    normed_train_data = norm(train_dataset)\n",
    "    normed_test_data = norm(test_dataset)\n",
    "\n",
    "    return normed_train_data, train_labels, normed_test_data, test_labels\n",
    "\n",
    "## Using training statistics to equals normalization.\n",
    "\n",
    "def pred_data_process(data: list):\n",
    "    import pandas as pd\n",
    "    \n",
    "    column_names = ['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin']\n",
    "    dataset = pd.DataFrame([data], columns=column_names)\n",
    "\n",
    "    dataset = dataset.dropna()\n",
    "\n",
    "    if (dataset['Origin'] == 1).any():\n",
    "        dataset = dataset.drop(columns=['Origin'])\n",
    "        dataset['Europe'] = 0\n",
    "        dataset['Japan'] = 0\n",
    "        dataset['USA'] = 1\n",
    "\n",
    "    elif (dataset['Origin'].any == 2).any():\n",
    "        dataset = dataset.drop(columns=['Origin'])\n",
    "        dataset['Europe'] = 1\n",
    "        dataset['Japan'] = 0\n",
    "        dataset['USA'] = 0\n",
    "\n",
    "    elif (dataset['Origin'] == 3).any():\n",
    "        dataset = dataset.drop(columns=['Origin'])\n",
    "        dataset['Europe'] = 0\n",
    "        dataset['Japan'] = 1\n",
    "        dataset['USA'] = 0\n",
    "\n",
    "    ## Train stats\n",
    "\n",
    "    train_stats = pd.read_csv('stats.csv', index_col=[0])\n",
    "    \n",
    "    def norm(x):\n",
    "        return (x - train_stats['mean'])/train_stats['std']\n",
    "    normed_data = norm(dataset)\n",
    "\n",
    "    return normed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting custom_draft/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile custom_draft/train.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from custom_draft import ctx\n",
    "\n",
    "def build_model(train_dataset):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    \n",
    "    model.compile(loss='mse',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae', 'mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(train_data, train_labels, epochs: int = 1000):\n",
    "    model = build_model(train_data)\n",
    "    epochs = epochs\n",
    "    \n",
    "    # The patience parameter is the amount of epochs to check for improvement\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    early_history = model.fit(train_data, train_labels, \n",
    "        epochs=epochs, validation_split = 0.2, \n",
    "        callbacks=[early_stop])\n",
    "    \n",
    "    model.save(f'{ctx.MODEL_URI}/mpg/model')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesusarguelles/code/vertex-gpu/pipe_notebook/custom_draft/preprocess.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              count         mean         std     min      25%     50%  \\\n",
      "Cylinders     314.0     5.477707    1.699788     3.0     4.00     4.0   \n",
      "Displacement  314.0   195.318471  104.331589    68.0   105.50   151.0   \n",
      "Horsepower    314.0   104.869427   38.096214    46.0    76.25    94.5   \n",
      "Weight        314.0  2990.251592  843.898596  1649.0  2256.50  2822.5   \n",
      "Acceleration  314.0    15.559236    2.789230     8.0    13.80    15.5   \n",
      "Model Year    314.0    75.898089    3.675642    70.0    73.00    76.0   \n",
      "Europe        314.0     0.178344    0.383413     0.0     0.00     0.0   \n",
      "Japan         314.0     0.197452    0.398712     0.0     0.00     0.0   \n",
      "USA           314.0     0.624204    0.485101     0.0     0.00     1.0   \n",
      "\n",
      "                  75%     max  \n",
      "Cylinders        8.00     8.0  \n",
      "Displacement   265.75   455.0  \n",
      "Horsepower     128.00   225.0  \n",
      "Weight        3608.00  5140.0  \n",
      "Acceleration    17.20    24.8  \n",
      "Model Year      79.00    82.0  \n",
      "Europe           0.00     1.0  \n",
      "Japan            0.00     1.0  \n",
      "USA              1.00     1.0  \n",
      "Epoch 1/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 553.7418 - mae: 22.3318 - mse: 553.7418 - val_loss: 544.3649 - val_mae: 22.1193 - val_mse: 544.3649\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 503.9312 - mae: 21.2452 - mse: 503.9312 - val_loss: 489.8935 - val_mae: 20.9184 - val_mse: 489.8935\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 453.2262 - mae: 20.0882 - mse: 453.2262 - val_loss: 430.5690 - val_mae: 19.5355 - val_mse: 430.5690\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 397.0796 - mae: 18.7369 - mse: 397.0796 - val_loss: 366.4339 - val_mae: 17.9231 - val_mse: 366.4339\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 337.5635 - mae: 17.1729 - mse: 337.5635 - val_loss: 299.9156 - val_mae: 16.0834 - val_mse: 299.9156\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.1054 - mae: 15.3936 - mse: 276.1054 - val_loss: 234.8296 - val_mae: 14.0175 - val_mse: 234.8296\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 217.6989 - mae: 13.4416 - mse: 217.6989 - val_loss: 175.2135 - val_mae: 11.8303 - val_mse: 175.2135\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 164.0456 - mae: 11.4267 - mse: 164.0456 - val_loss: 124.1926 - val_mae: 9.5982 - val_mse: 124.1926\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 119.8180 - mae: 9.4058 - mse: 119.8180 - val_loss: 86.6369 - val_mae: 7.7815 - val_mse: 86.6369\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9817 - mae: 7.6966 - mse: 86.9817 - val_loss: 61.9135 - val_mae: 6.4508 - val_mse: 61.9135\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 64.4854 - mae: 6.3406 - mse: 64.4854 - val_loss: 48.0946 - val_mae: 5.7065 - val_mse: 48.0946\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 49.6005 - mae: 5.5924 - mse: 49.6005 - val_loss: 39.5647 - val_mae: 5.2180 - val_mse: 39.5647\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 38.9447 - mae: 4.9559 - mse: 38.9447 - val_loss: 33.6790 - val_mae: 4.8268 - val_mse: 33.6789\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.3333 - mae: 4.4147 - mse: 31.3333 - val_loss: 28.9986 - val_mae: 4.4727 - val_mse: 28.9986\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 25.3722 - mae: 3.9510 - mse: 25.3722 - val_loss: 25.3468 - val_mae: 4.1193 - val_mse: 25.3468\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21.0736 - mae: 3.5681 - mse: 21.0736 - val_loss: 22.4214 - val_mae: 3.8084 - val_mse: 22.4214\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18.1435 - mae: 3.3177 - mse: 18.1435 - val_loss: 19.9323 - val_mae: 3.6142 - val_mse: 19.9323\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.6601 - mae: 3.1006 - mse: 15.6601 - val_loss: 17.3172 - val_mae: 3.4469 - val_mse: 17.3172\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14.3095 - mae: 2.9305 - mse: 14.3095 - val_loss: 15.9452 - val_mae: 3.2489 - val_mse: 15.9452\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.0472 - mae: 2.8016 - mse: 13.0472 - val_loss: 14.4348 - val_mae: 3.0662 - val_mse: 14.4348\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.1027 - mae: 2.6508 - mse: 12.1027 - val_loss: 13.9538 - val_mae: 2.9065 - val_mse: 13.9538\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.3246 - mae: 2.5729 - mse: 11.3246 - val_loss: 12.7821 - val_mae: 2.8973 - val_mse: 12.7821\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.8270 - mae: 2.4771 - mse: 10.8270 - val_loss: 11.4897 - val_mae: 2.6850 - val_mse: 11.4897\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.2545 - mae: 2.3907 - mse: 10.2545 - val_loss: 11.1248 - val_mae: 2.6133 - val_mse: 11.1248\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.9379 - mae: 2.3469 - mse: 9.9379 - val_loss: 10.3588 - val_mae: 2.5157 - val_mse: 10.3588\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.7077 - mae: 2.2876 - mse: 9.7077 - val_loss: 9.9692 - val_mae: 2.4458 - val_mse: 9.9692\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.3420 - mae: 2.2382 - mse: 9.3420 - val_loss: 9.6929 - val_mae: 2.4023 - val_mse: 9.6929\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.9794 - mae: 2.2094 - mse: 8.9794 - val_loss: 9.7606 - val_mae: 2.4358 - val_mse: 9.7606\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.7147 - mae: 2.1514 - mse: 8.7147 - val_loss: 9.2903 - val_mae: 2.3204 - val_mse: 9.2903\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.8256 - mae: 2.1728 - mse: 8.8256 - val_loss: 9.3375 - val_mae: 2.3527 - val_mse: 9.3375\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.5467 - mae: 2.0808 - mse: 8.5467 - val_loss: 9.2263 - val_mae: 2.2483 - val_mse: 9.2263\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.3452 - mae: 2.0661 - mse: 8.3452 - val_loss: 9.1264 - val_mae: 2.2264 - val_mse: 9.1264\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.3195 - mae: 2.0886 - mse: 8.3195 - val_loss: 8.8894 - val_mae: 2.2238 - val_mse: 8.8894\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.1070 - mae: 2.0371 - mse: 8.1070 - val_loss: 8.8781 - val_mae: 2.2451 - val_mse: 8.8781\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.1946 - mae: 2.0345 - mse: 8.1946 - val_loss: 8.7040 - val_mae: 2.2360 - val_mse: 8.7040\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.0910 - mae: 2.0300 - mse: 8.0910 - val_loss: 8.5127 - val_mae: 2.2152 - val_mse: 8.5127\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.7344 - mae: 1.9942 - mse: 7.7344 - val_loss: 8.8730 - val_mae: 2.1922 - val_mse: 8.8730\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.8249 - mae: 2.0143 - mse: 7.8249 - val_loss: 8.5276 - val_mae: 2.1912 - val_mse: 8.5276\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.6153 - mae: 1.9704 - mse: 7.6153 - val_loss: 8.7973 - val_mae: 2.1620 - val_mse: 8.7973\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.8668 - mae: 2.0180 - mse: 7.8668 - val_loss: 8.6147 - val_mae: 2.2373 - val_mse: 8.6147\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.5045 - mae: 1.9553 - mse: 7.5045 - val_loss: 8.6505 - val_mae: 2.2432 - val_mse: 8.6505\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.6458 - mae: 1.9824 - mse: 7.6458 - val_loss: 8.4382 - val_mae: 2.1805 - val_mse: 8.4382\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.4047 - mae: 1.9618 - mse: 7.4047 - val_loss: 8.4371 - val_mae: 2.2133 - val_mse: 8.4371\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.3973 - mae: 1.9477 - mse: 7.3973 - val_loss: 8.5165 - val_mae: 2.1902 - val_mse: 8.5165\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.2878 - mae: 1.9031 - mse: 7.2878 - val_loss: 8.6276 - val_mae: 2.1578 - val_mse: 8.6276\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.4235 - mae: 1.9386 - mse: 7.4235 - val_loss: 8.5020 - val_mae: 2.2198 - val_mse: 8.5020\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.3055 - mae: 1.9199 - mse: 7.3055 - val_loss: 8.3470 - val_mae: 2.1730 - val_mse: 8.3470\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.1911 - mae: 1.9157 - mse: 7.1911 - val_loss: 8.5779 - val_mae: 2.1573 - val_mse: 8.5779\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.2374 - mae: 1.9309 - mse: 7.2374 - val_loss: 8.5025 - val_mae: 2.1803 - val_mse: 8.5025\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.2331 - mae: 1.9117 - mse: 7.2331 - val_loss: 8.6655 - val_mae: 2.2315 - val_mse: 8.6655\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.3471 - mae: 1.9403 - mse: 7.3471 - val_loss: 8.5673 - val_mae: 2.2033 - val_mse: 8.5673\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.2041 - mae: 1.8851 - mse: 7.2041 - val_loss: 8.4731 - val_mae: 2.1976 - val_mse: 8.4731\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.1499 - mae: 1.8829 - mse: 7.1499 - val_loss: 8.6364 - val_mae: 2.2492 - val_mse: 8.6364\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.0474 - mae: 1.8826 - mse: 7.0474 - val_loss: 8.4202 - val_mae: 2.1767 - val_mse: 8.4202\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.0176 - mae: 1.8730 - mse: 7.0176 - val_loss: 8.6117 - val_mae: 2.1823 - val_mse: 8.6117\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.9654 - mae: 1.8838 - mse: 6.9654 - val_loss: 8.5471 - val_mae: 2.2522 - val_mse: 8.5471\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.1487 - mae: 1.8888 - mse: 7.1487 - val_loss: 8.7287 - val_mae: 2.1794 - val_mse: 8.7287\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from custom_draft import preprocess\n",
    "from custom_draft import train\n",
    "\n",
    "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight','Acceleration', 'Model Year', 'Origin']\n",
    "dataset = pd.read_csv(dataset_path, names=column_names, na_values = \"?\", comment='\\t',sep=\" \", skipinitialspace=True)\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = preprocess.train_pre_process(dataset)\n",
    "model = train.train_model(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146    28.0\n",
       "282    22.3\n",
       "69     12.0\n",
       "378    38.0\n",
       "331    33.8\n",
       "       ... \n",
       "281    19.8\n",
       "229    16.0\n",
       "150    26.0\n",
       "145    32.0\n",
       "182    28.0\n",
       "Name: MPG, Length: 314, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing custom_draft/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile custom_draft/main.py\n",
    "\n",
    "from fastapi import Request, FastAPI\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "from custom_draft import preprocess\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "model_uri=os.environ['AIP_STORAGE_URI']\n",
    "print(f'[INFO] ------ {model_uri}', file=sys.stderr)\n",
    "model = tf.keras.models.load_model(f'{model_uri}/mpg/model')\n",
    "\n",
    "@app.get('/')\n",
    "def get_root():\n",
    "    return {'message': 'Welcome mpg API: miles per gallon prediction'}\n",
    "\n",
    "@app.get('/health_check')\n",
    "def health():\n",
    "    return 200\n",
    "\n",
    "if os.environ.get('AIP_PREDICT_ROUTE') is not None:\n",
    "    method = os.environ['AIP_PREDICT_ROUTE']\n",
    "else:\n",
    "    method = '/predict'\n",
    "\n",
    "@app.post(method)\n",
    "async def predict(request: Request):\n",
    "    print(\"----------------- PREDICTING -----------------\")\n",
    "    body = await request.json()\n",
    "    instances = body[\"instances\"]\n",
    "\n",
    "    norm_data = preprocess.pred_data_process(instances)\n",
    "    \n",
    "    outputs = model.predict(norm_data)\n",
    "    response = outputs.tolist()\n",
    "    print(\"----------------- OUTPUTS -----------------\")\n",
    "    return {\"predictions\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting custom_draft/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile custom_draft/Dockerfile\n",
    "\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
    "\n",
    "COPY / /app\n",
    "WORKDIR /app\n",
    "RUN pip install google-cloud-storage tensorflow\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "\n",
    "EXPOSE 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_IMAGE_URI = \"gcr.io/jchavezar-demo/fast_pred:v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 6 file(s) totalling 4.1 KiB before compression.\n",
      "Uploading tarball of [custom_draft/.] to [gs://jchavezar-demo_cloudbuild/source/1662493898.857458-6201bc78a73242788b03a6860e0042eb.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/jchavezar-demo/locations/global/builds/b858dea8-3bca-4206-adad-a9dbaa5b2ad1].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/b858dea8-3bca-4206-adad-a9dbaa5b2ad1?project=569083142710 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"b858dea8-3bca-4206-adad-a9dbaa5b2ad1\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://jchavezar-demo_cloudbuild/source/1662493898.857458-6201bc78a73242788b03a6860e0042eb.tgz#1662493899371351\n",
      "Copying gs://jchavezar-demo_cloudbuild/source/1662493898.857458-6201bc78a73242788b03a6860e0042eb.tgz#1662493899371351...\n",
      "/ [1 files][  1.8 KiB/  1.8 KiB]                                                \n",
      "Operation completed over 1 objects/1.8 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  9.216kB\n",
      "Step 1/6 : FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
      "python3.7: Pulling from tiangolo/uvicorn-gunicorn-fastapi\n",
      "df5590a8898b: Pulling fs layer\n",
      "705bb4cb554e: Pulling fs layer\n",
      "519df5fceacd: Pulling fs layer\n",
      "ccc287cbeddc: Pulling fs layer\n",
      "e3f8e6af58ed: Pulling fs layer\n",
      "aebed27b2d86: Pulling fs layer\n",
      "3b81dff756ff: Pulling fs layer\n",
      "6e4f59a23b58: Pulling fs layer\n",
      "ccc287cbeddc: Waiting\n",
      "e3f8e6af58ed: Waiting\n",
      "aebed27b2d86: Waiting\n",
      "3b81dff756ff: Waiting\n",
      "5cdb61eb416d: Pulling fs layer\n",
      "415755650c07: Pulling fs layer\n",
      "6e4f59a23b58: Waiting\n",
      "5cdb61eb416d: Waiting\n",
      "415755650c07: Waiting\n",
      "82af7648a68a: Pulling fs layer\n",
      "697e3cdf6fdb: Pulling fs layer\n",
      "82af7648a68a: Waiting\n",
      "8d414b25a011: Pulling fs layer\n",
      "3e3cfa737f56: Pulling fs layer\n",
      "697e3cdf6fdb: Waiting\n",
      "1595db7eb9b1: Pulling fs layer\n",
      "d2d3fcd4b870: Pulling fs layer\n",
      "35f87fd78dc8: Pulling fs layer\n",
      "146e266752fc: Pulling fs layer\n",
      "57df244389c0: Pulling fs layer\n",
      "8d414b25a011: Waiting\n",
      "e8391aa94779: Pulling fs layer\n",
      "3e3cfa737f56: Waiting\n",
      "1595db7eb9b1: Waiting\n",
      "d2d3fcd4b870: Waiting\n",
      "57df244389c0: Waiting\n",
      "35f87fd78dc8: Waiting\n",
      "146e266752fc: Waiting\n",
      "e8391aa94779: Waiting\n",
      "705bb4cb554e: Verifying Checksum\n",
      "705bb4cb554e: Download complete\n",
      "519df5fceacd: Verifying Checksum\n",
      "519df5fceacd: Download complete\n",
      "ccc287cbeddc: Verifying Checksum\n",
      "ccc287cbeddc: Download complete\n",
      "aebed27b2d86: Verifying Checksum\n",
      "aebed27b2d86: Download complete\n",
      "3b81dff756ff: Verifying Checksum\n",
      "3b81dff756ff: Download complete\n",
      "6e4f59a23b58: Verifying Checksum\n",
      "6e4f59a23b58: Download complete\n",
      "5cdb61eb416d: Verifying Checksum\n",
      "5cdb61eb416d: Download complete\n",
      "df5590a8898b: Verifying Checksum\n",
      "df5590a8898b: Download complete\n",
      "415755650c07: Verifying Checksum\n",
      "415755650c07: Download complete\n",
      "697e3cdf6fdb: Verifying Checksum\n",
      "697e3cdf6fdb: Download complete\n",
      "82af7648a68a: Verifying Checksum\n",
      "82af7648a68a: Download complete\n",
      "8d414b25a011: Verifying Checksum\n",
      "8d414b25a011: Download complete\n",
      "3e3cfa737f56: Verifying Checksum\n",
      "3e3cfa737f56: Download complete\n",
      "1595db7eb9b1: Verifying Checksum\n",
      "1595db7eb9b1: Download complete\n",
      "d2d3fcd4b870: Verifying Checksum\n",
      "d2d3fcd4b870: Download complete\n",
      "35f87fd78dc8: Verifying Checksum\n",
      "35f87fd78dc8: Download complete\n",
      "146e266752fc: Verifying Checksum\n",
      "146e266752fc: Download complete\n",
      "e8391aa94779: Verifying Checksum\n",
      "e8391aa94779: Download complete\n",
      "57df244389c0: Verifying Checksum\n",
      "57df244389c0: Download complete\n",
      "e3f8e6af58ed: Verifying Checksum\n",
      "e3f8e6af58ed: Download complete\n",
      "df5590a8898b: Pull complete\n",
      "705bb4cb554e: Pull complete\n",
      "519df5fceacd: Pull complete\n",
      "ccc287cbeddc: Pull complete\n",
      "e3f8e6af58ed: Pull complete\n",
      "aebed27b2d86: Pull complete\n",
      "3b81dff756ff: Pull complete\n",
      "6e4f59a23b58: Pull complete\n",
      "5cdb61eb416d: Pull complete\n",
      "415755650c07: Pull complete\n",
      "82af7648a68a: Pull complete\n",
      "697e3cdf6fdb: Pull complete\n",
      "8d414b25a011: Pull complete\n",
      "3e3cfa737f56: Pull complete\n",
      "1595db7eb9b1: Pull complete\n",
      "d2d3fcd4b870: Pull complete\n",
      "35f87fd78dc8: Pull complete\n",
      "146e266752fc: Pull complete\n",
      "57df244389c0: Pull complete\n",
      "e8391aa94779: Pull complete\n",
      "Digest: sha256:f5770422a8875fe3d677e1bda724eeba332b53b0a348a9cdde854ba7136c66be\n",
      "Status: Downloaded newer image for tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
      " ---> bc3531b1f244\n",
      "Step 2/6 : COPY / /app\n",
      " ---> cd939b8c3578\n",
      "Step 3/6 : WORKDIR /app\n",
      " ---> Running in 505787b51820\n",
      "Removing intermediate container 505787b51820\n",
      " ---> 230fd25bb60d\n",
      "Step 4/6 : RUN pip install google-cloud-storage tensorflow\n",
      " ---> Running in 8db0bc5a7d5a\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.5.0-py2.py3-none-any.whl (106 kB)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
      "Collecting requests<3.0.0dev,>=2.18.0\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting google-resumable-media>=2.3.2\n",
      "  Downloading google_resumable_media-2.3.3-py2.py3-none-any.whl (76 kB)\n",
      "Collecting google-auth<3.0dev,>=1.25.0\n",
      "  Downloading google_auth-2.11.0-py2.py3-none-any.whl (167 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.10.0-py3-none-any.whl (115 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "Collecting six>=1.12.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.48.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Collecting numpy>=1.20\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from tensorflow) (57.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.9.0-py3-none-any.whl (115 kB)\n",
      "  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.6.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=19250f5b58d3b8adb074b2c55588f2884e13e8808aebd964f31fb7523b067de8\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built termcolor\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, six, rsa, requests, pyasn1-modules, protobuf, oauthlib, cachetools, requests-oauthlib, MarkupSafe, googleapis-common-protos, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, pyparsing, numpy, markdown, grpcio, google-crc32c, google-auth-oauthlib, google-api-core, absl-py, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, packaging, opt-einsum, libclang, keras-preprocessing, keras, h5py, google-resumable-media, google-pasta, google-cloud-core, gast, flatbuffers, astunparse, tensorflow, google-cloud-storage\n",
      "Successfully installed MarkupSafe-2.1.1 absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 certifi-2022.6.15 charset-normalizer-2.1.1 flatbuffers-2.0.7 gast-0.4.0 google-api-core-2.8.2 google-auth-2.11.0 google-auth-oauthlib-0.4.6 google-cloud-core-2.3.2 google-cloud-storage-2.5.0 google-crc32c-1.5.0 google-pasta-0.2.0 google-resumable-media-2.3.3 googleapis-common-protos-1.56.4 grpcio-1.48.1 h5py-3.7.0 idna-3.3 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 numpy-1.21.6 oauthlib-3.2.0 opt-einsum-3.3.0 packaging-21.3 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 six-1.16.0 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0 urllib3-1.26.12 werkzeug-2.2.2 wrapt-1.14.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 21.2.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 8db0bc5a7d5a\n",
      " ---> e3a9ad6342b2\n",
      "Step 5/6 : CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
      " ---> Running in 5459332aa425\n",
      "Removing intermediate container 5459332aa425\n",
      " ---> d66bd5682f35\n",
      "Step 6/6 : EXPOSE 8080\n",
      " ---> Running in 5b42ad3bae07\n",
      "Removing intermediate container 5b42ad3bae07\n",
      " ---> 73deaf6f360c\n",
      "Successfully built 73deaf6f360c\n",
      "Successfully tagged gcr.io/jchavezar-demo/fast_pred:v1\n",
      "PUSH\n",
      "Pushing gcr.io/jchavezar-demo/fast_pred:v1\n",
      "The push refers to repository [gcr.io/jchavezar-demo/fast_pred]\n",
      "2daba05cdcb4: Preparing\n",
      "b10d744f480e: Preparing\n",
      "574be7dd3a19: Preparing\n",
      "4a24608ea27b: Preparing\n",
      "c660563b938b: Preparing\n",
      "e313cca5ff4a: Preparing\n",
      "ad6638039b02: Preparing\n",
      "4c503f7b7cec: Preparing\n",
      "49022fdb47b6: Preparing\n",
      "f4cc5099892d: Preparing\n",
      "471ef6255d6e: Preparing\n",
      "0f8cd2835d79: Preparing\n",
      "0616239ad62a: Preparing\n",
      "4eb436881a0f: Preparing\n",
      "7fe8548565b4: Preparing\n",
      "8364a493536b: Preparing\n",
      "c1792902851c: Preparing\n",
      "c272c95c3fb0: Preparing\n",
      "3054497613e6: Preparing\n",
      "d35dc7f4c79e: Preparing\n",
      "dabfe5b2ea81: Preparing\n",
      "5e6a409f30b6: Preparing\n",
      "0f8cd2835d79: Waiting\n",
      "0616239ad62a: Waiting\n",
      "4eb436881a0f: Waiting\n",
      "7fe8548565b4: Waiting\n",
      "8364a493536b: Waiting\n",
      "c1792902851c: Waiting\n",
      "c272c95c3fb0: Waiting\n",
      "3054497613e6: Waiting\n",
      "d35dc7f4c79e: Waiting\n",
      "dabfe5b2ea81: Waiting\n",
      "5e6a409f30b6: Waiting\n",
      "ad6638039b02: Waiting\n",
      "4c503f7b7cec: Waiting\n",
      "49022fdb47b6: Waiting\n",
      "f4cc5099892d: Waiting\n",
      "471ef6255d6e: Waiting\n",
      "e313cca5ff4a: Waiting\n",
      "b10d744f480e: Pushed\n",
      "574be7dd3a19: Pushed\n",
      "c660563b938b: Pushed\n",
      "4a24608ea27b: Pushed\n",
      "e313cca5ff4a: Pushed\n",
      "4c503f7b7cec: Pushed\n",
      "ad6638039b02: Pushed\n",
      "49022fdb47b6: Pushed\n",
      "471ef6255d6e: Pushed\n",
      "f4cc5099892d: Pushed\n",
      "0f8cd2835d79: Pushed\n",
      "0616239ad62a: Pushed\n",
      "7fe8548565b4: Pushed\n",
      "c1792902851c: Layer already exists\n",
      "c272c95c3fb0: Layer already exists\n",
      "3054497613e6: Layer already exists\n",
      "d35dc7f4c79e: Layer already exists\n",
      "dabfe5b2ea81: Layer already exists\n",
      "4eb436881a0f: Pushed\n",
      "5e6a409f30b6: Layer already exists\n",
      "8364a493536b: Pushed\n",
      "2daba05cdcb4: Pushed\n",
      "v1: digest: sha256:fb649ac8a408c5f7f86a713c14534e27b52d2edaf7ea7cf088a21b1833fb5e03 size: 4927\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                        IMAGES                              STATUS\n",
      "b858dea8-3bca-4206-adad-a9dbaa5b2ad1  2022-09-06T19:51:39+00:00  5M38S     gs://jchavezar-demo_cloudbuild/source/1662493898.857458-6201bc78a73242788b03a6860e0042eb.tgz  gcr.io/jchavezar-demo/fast_pred:v1  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit -t $PRED_IMAGE_URI custom_draft/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f891a263dd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('gs://vtx-models/mpg/model')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[15.102618]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(preprocess.pred_data_process([8.0, 350.0, 165.0, 3693.0, 11.5, 70.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 12:26:58.059857: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-07 12:26:58.064552: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-07 12:26:58.064573: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   Model Year  Origin  \n",
       "0          70       1  \n",
       "1          70       1  \n",
       "2          70       1  \n",
       "3          70       1  \n",
       "4          70       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from custom_draft import preprocess\n",
    "from custom_draft import train\n",
    "\n",
    "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight','Acceleration', 'Model Year', 'Origin']\n",
    "dataset = pd.read_csv(dataset_path, names=column_names, na_values = \"?\", comment='\\t',sep=\" \", skipinitialspace=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec89e24100c8ca00f439bc5e12890d368cf0c3feba00695f2e5a4a6dddd0c167"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
