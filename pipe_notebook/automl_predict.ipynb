{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a quick run files for automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID='jchavezar-demo'\n",
    "REGION='us-central1'\n",
    "BUCKET_NAME='vtx-automl'\n",
    "BUCKET_URI=f'gs://{BUCKET_NAME}'\n",
    "IMPORT_FILE = (\n",
    "    \"gs://cloud-samples-data/vision/automl_classification/flowers/all_data_v2.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ImageDataset\n",
      "Create ImageDataset backing LRO: projects/569083142710/locations/us-central1/datasets/1144972035538026496/operations/4774818703214641152\n",
      "ImageDataset created. Resource name: projects/569083142710/locations/us-central1/datasets/1144972035538026496\n",
      "To use this ImageDataset in another session:\n",
      "ds = aiplatform.ImageDataset('projects/569083142710/locations/us-central1/datasets/1144972035538026496')\n",
      "Importing ImageDataset data: projects/569083142710/locations/us-central1/datasets/1144972035538026496\n",
      "Import ImageDataset data backing LRO: projects/569083142710/locations/us-central1/datasets/1144972035538026496/operations/3214884382284185600\n",
      "ImageDataset data imported. Resource name: projects/569083142710/locations/us-central1/datasets/1144972035538026496\n",
      "projects/569083142710/locations/us-central1/datasets/1144972035538026496\n"
     ]
    }
   ],
   "source": [
    "dataset = aiplatform.ImageDataset.create(\n",
    "    display_name=\"flowers_\" + TIMESTAMP,\n",
    "    gcs_source=[IMPORT_FILE],\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.image.single_label_classification,\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoML Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.cloud.aiplatform.training_jobs.AutoMLImageTrainingJob object at 0x7f4302fb8fd0>\n"
     ]
    }
   ],
   "source": [
    "automl = aiplatform.AutoMLImageTrainingJob(\n",
    "    display_name=\"flowers_\" + TIMESTAMP,\n",
    "    prediction_type=\"classification\",\n",
    "    multi_label=False,\n",
    "    model_type=\"MOBILE_TF_LOW_LATENCY_1\",\n",
    "    base_model=None,\n",
    ")\n",
    "\n",
    "print(automl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/6399378950371409920?project=569083142710\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob run completed. Resource name: projects/569083142710/locations/us-central1/trainingPipelines/6399378950371409920\n",
      "Model available at projects/569083142710/locations/us-central1/models/9196539555090530304\n"
     ]
    }
   ],
   "source": [
    "model = automl.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"flowers_\" + TIMESTAMP,\n",
    "    training_fraction_split=0.8,\n",
    "    validation_fraction_split=0.1,\n",
    "    test_fraction_split=0.1,\n",
    "    budget_milli_node_hours=8000,\n",
    "    disable_early_stopping=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Model Evaluation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_item = !gsutil cat $IMPORT_FILE | head -n1\n",
    "if len(str(test_item[0]).split(\",\")) == 3:\n",
    "    _, test_item, test_label = str(test_item[0]).split(\",\")\n",
    "else:\n",
    "    test_item, test_label = str(test_item[0]).split(\",\")\n",
    "\n",
    "print(test_item, test_label)\n",
    "\n",
    "import base64\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "# Copy the test image to the Cloud storage bucket as \"test.jpg\"\n",
    "test_image_local = \"{}/test.jpg\".format(BUCKET_URI)\n",
    "! gsutil cp $test_item $test_image_local\n",
    "\n",
    "# Download the test image in bytes format\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "bucket = storage_client.bucket(bucket_name=BUCKET_NAME)\n",
    "test_content = bucket.get_blob(\"test.jpg\").download_as_bytes()\n",
    "\n",
    "# The format of each instance should conform to the deployed model's prediction input schema.\n",
    "instances = [{\"content\": base64.b64encode(test_content).decode(\"utf-8\")}]\n",
    "\n",
    "prediction = endpoint.predict(instances=instances)\n",
    "\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
