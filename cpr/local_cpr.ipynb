{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c3e83c3-9c02-4eb7-82a9-ac6f7f72ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e657aa4f-57ec-4f1d-bd94-cc745c8b7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"jchavezar-demo\"\n",
    "REPOSITORY = \"custom-preprocess-container-prediction\"\n",
    "IMAGE = \"cpr:v1\"\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8e83787-f9f0-4caa-964e-31383f1933b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/predictor.py\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform.prediction.sklearn.predictor import SklearnPredictor\n",
    "\n",
    "class CprPredictor(SklearnPredictor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load(self, artifacts_uri: str):\n",
    "        \"\"\"Loads the preprocessor artifacts.\"\"\"\n",
    "        super().load(artifacts_uri)\n",
    "        gcs_client = storage.Client()\n",
    "        with open(\"model_xgb.json\", 'wb') as preprocessor_f:\n",
    "            gcs_client.download_blob_to_file(\n",
    "                f\"{artifacts_uri}/model_xgb.json\", preprocessor_f\n",
    "            )\n",
    "\n",
    "        with open(\"model_xgb.json\", \"rb\") as f:\n",
    "            bst = xgb.Booster(model_file=f)\n",
    "\n",
    "        self._bst = bst\n",
    "    \n",
    "    def predict(self, instances):\n",
    "        \"\"\"Performs prediction.\"\"\"\n",
    "        instances = instances[\"instances\"]\n",
    "        data_dic = {feature:[v] for feature in columns for value in dict[\"instances\"] for v in value if feature != \"Cover_Type\"}\n",
    "        df = pd.DataFrame(data_dic)\n",
    "        dtrain = xgb.DMatrix(df)\n",
    "        outputs = self._bst.predict(dtrain)\n",
    "\n",
    "        return {\"predictions\": outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61524a25-aa68-43ea-9fda-eeb44e5ed1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/requirements.txt\n",
    "fastapi\n",
    "uvicorn\n",
    "joblib~=1.0\n",
    "numpy~=1.20\n",
    "pandas\n",
    "gcsfs\n",
    "xgboost\n",
    "google-cloud-storage>=1.26.0,<2.0.0dev\n",
    "google-cloud-aiplatform[prediction] @ git+https://github.com/googleapis/python-aiplatform.git@custom-prediction-routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaa95b4-c9d8-4f23-a876-915d9613ea8f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r src/requirements.txt --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3454bf7-4837-4e31-9b69-4f721cd31a82",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.utils.prediction_utils:\"src/cpr_model_server.py\" already exists, skip generating \"cpr_model_server.py\" in \"src\".\n",
      "INFO:google.cloud.aiplatform.docker_utils.build:Running command: docker build -t us-central1-docker.pkg.dev/jchavezar-demo/custom-preprocess-container-prediction/cpr:v1 --rm -f- src\n",
      "/usr/lib/python3.10/subprocess.py:950: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
      "/usr/lib/python3.10/subprocess.py:956: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Sending build context to Docker daemon  17.97kB\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 1/11 : FROM python:3.7\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 2e9441c95bb8\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 2/11 : ENV PYTHONDONTWRITEBYTECODE=1\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 45a973ee3034\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 3/11 : EXPOSE 8080\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> c1bb41a5ec42\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 4/11 : ENTRYPOINT [\"python\", \"src/entrypoint.py\"]\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 060a970faa94\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 5/11 : RUN mkdir -m 777 -p /usr/app /home\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 414c468c77aa\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 6/11 : WORKDIR /usr/app\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 5786ffbe7f1e\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 7/11 : ENV HOME=/home\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 5019d7201560\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 8/11 : RUN pip install --no-cache-dir --force-reinstall 'google-cloud-aiplatform[prediction] @ git+https://github.com/googleapis/python-aiplatform.git@custom-prediction-routine'\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 18192c94a386\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 9/11 : COPY [\"requirements.txt\", \"./requirements.txt\"]\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 7c7b0e05c992\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 10/11 : RUN pip install --no-cache-dir --force-reinstall -r ./requirements.txt\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 6627334de5e5\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 11/11 : COPY [\".\", \"src\"]\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 572ca5768194\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Successfully built 572ca5768194\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Successfully tagged us-central1-docker.pkg.dev/jchavezar-demo/custom-preprocess-container-prediction/cpr:v1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "\n",
    "from src.predictor import CprPredictor  # Update this path as the variable $USER_SRC_DIR to import the custom predictor.\n",
    "\n",
    "local_model = LocalModel.create_cpr_model(\n",
    "    \"src\",\n",
    "    f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}\",\n",
    "    predictor=CprPredictor,\n",
    "    requirements_path=os.path.join(\"src\", \"requirements.txt\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a80e10ca-9c06-4d66-88df-83f9a36a8610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_uri: \"us-central1-docker.pkg.dev/jchavezar-demo/custom-preprocess-container-prediction/cpr:v1\"\n",
       "predict_route: \"/predict\"\n",
       "health_route: \"/health\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb425c3c-ed80-4f3b-afba-518fbaac3078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 1.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile 1.json\n",
    "{\n",
    "  \"type\": \"service_account\",\n",
    "  \"project_id\": \"jchavezar-demo\",\n",
    "  \"private_key_id\": \"a549c8c39d6b9a914eeba4bcfacee5471b9bc505\",\n",
    "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvAIBADANBgkqhkiG9w0BAQEFAASCBKYwggSiAgEAAoIBAQCtXAtUXcqF7x6r\\naETLKSr/llFwmdQstDFu+1HMDqr47C70DPRDJ6V32xL85bsMXXrVWmAFt2v4tetx\\naFoICCSd+zBw7KOOEkDKIk/v695FBobQdtc0p8tR2GZK65bjHxik6SehOCz0Rf/L\\nisf7KGXztATnHeJXzdjgX+d1NqXrSyrQOE52qhNzPoKpayYwJTU12tgzDL7Or4Be\\nIiACv1kBoQDB5E+a6pR01GhL7tcbPbH/H56MUe2DqBHnUZ+zTfkERH2k1Ghgv37L\\nKhDqKUdZGJz2SWpmJyzSnQW+jRTV1SV26sK17CnzcIZLEnllDU2vlz+55U3AAEWC\\nnqLSo93jAgMBAAECggEARfxeQIl6vLZLueQmvaPZjYRITX50pzV5rXW9UHVtdX+X\\n9wORytijFu90y28NI9FLSP2qvTQO3UHIEqkPi6WJ7tNc+4G1B6J70H6oqdGdkl0v\\nqNIJUGMbFGgZ584TRI6lutG7o3zTvSvTN/9He7AT9J4syocIfO0HzJE7FllhA0tT\\ngdW+GlJ5hOHXR6IEINwACxGsx7PM7SiFANWetUCqpKpIsV31H7ATUb1KX2X8Om3K\\n7aoPRziNWqmHXIw3tP+UJWo136MVVS72dmlrIqPwOsobANk5qYhvx/R8A7TyIb6a\\n0Qvt9qA4lXMZ7CuULTWMwZ+NGWghv3cKoOf4cHvPaQKBgQDaTqTr7KNGZTbwywYA\\nlInwU2iZoXTaXDe8pHBm5kTcC/hgbzamcgeXIi9+mBcmJXEGJ9umXswMy15M5NFL\\nxLoCersa6UoGlNpB44RR9J2LKXm9kZbMtxXUvvP36aOLus96Y5dn1ej/xR2sxGcv\\n6p2W7KQPLuuYPDAsp2ilkZbHGwKBgQDLSq1XUv1EVfYm0JviwOG0qOqG5HO7eFnu\\npOs8d7Q64658hA7Ojj6diIOAPjvA2A47TkiyWVjDYqSiu2+XR2efMWj1fkI5bRGe\\nrRmJc22zzy/4Mq0MIHpbvD7qIq2Efj8ERq7Q+AQ3qGcRmGF8UUXe7yV/ThjoT/nv\\nTIAKV1jI2QKBgEUjqy/dHkjpPWE9q4T7hkRK5lHhxLRziGOCYOb1/tECKYPBNTm5\\n25WOCiS53nsCWK1uai5iz5Utw4vu3Cp2/8JRRHjdcchr1EQR3pJmOo8cb6YOOghT\\n4+IhJ/tYT6etXpCQgh8srEJ1F1TkTxnp4EcwYzU70vm/9jHuQ0JMvcgJAoGAW6WR\\n2cE/DlSWgM8gx6ve1NwlxqQtDIHoQS62Ie9xH+9O1TGPn0z/K3PEnMbxlzGP0Oqs\\n2UJwQr0wrXBEkXWOYHUc9TdzUYI7JEazMYUJGru3y3PFEad+oeaOkm0JvqZPcHUR\\nEIIPHKxdss/4etwE3MkBJZAmqGyNp3TccE0KaJkCgYAkHTUFHyzXLanE0VpvV9Ss\\nTub/Y6vUp6EhzAOYUpH3KeuQlJ1yBreuoJ1icafaeCHExsId1v3UiE8hhYV5uYyG\\ndfw9kzNjb58x0MQUAAd9sfp4GDSTFpGh76cp5i+BYR6RFoDTafvThI5rDn7YLf2y\\nAtFus9v99qAQ9x2XCA28eQ==\\n-----END PRIVATE KEY-----\\n\",\n",
    "  \"client_email\": \"glinux@jchavezar-demo.iam.gserviceaccount.com\",\n",
    "  \"client_id\": \"108058543153100113637\",\n",
    "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/glinux%40jchavezar-demo.iam.gserviceaccount.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16adab99-61e2-4127-a2ea-1851eba16557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/input.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/input.json\n",
    "\n",
    "{\n",
    "    \"instances\": [\n",
    "        [0,\n",
    "         3189,\n",
    "         40,\n",
    "         8,\n",
    "         30,\n",
    "         13,\n",
    "         3270,\n",
    "         206,\n",
    "         234,\n",
    "         193,\n",
    "         4873,\n",
    "         1,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         1,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         0,\n",
    "         1]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "083f2c07-a8b4-4f64-a757-81062ede4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS_FILE = \"/home/jesusarguelles/code/vertex-gpu/cpr/credentials.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d42a2649-5b1f-44c9-a400-40902a0c1a4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.projects.add-iam-policy-binding) You do not currently have an active account selected.\n",
      "Please run:\n",
      "\n",
      "  $ gcloud auth login\n",
      "\n",
      "to obtain new credentials.\n",
      "\n",
      "If you have already logged in with a different account:\n",
      "\n",
      "    $ gcloud config set account ACCOUNT\n",
      "\n",
      "to select an already authenticated account to use.\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "    --member=serviceAccount:glinux@jchavezar-demo.iam.gserviceaccount.com \\\n",
    "    --role=roles/storage.objectViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ddc9c47-6bf0-43d9-9550-817395e9c4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jesusarguelles/code/vertex-gpu/cpr/credentials.json'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREDENTIALS_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acdd0c43-381d-4349-9bfb-201ba0e0e32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.iam.service-accounts.keys.create) You do not currently have an active account selected.\n",
      "Please run:\n",
      "\n",
      "  $ gcloud auth login\n",
      "\n",
      "to obtain new credentials.\n",
      "\n",
      "If you have already logged in with a different account:\n",
      "\n",
      "    $ gcloud config set account ACCOUNT\n",
      "\n",
      "to select an already authenticated account to use.\n"
     ]
    }
   ],
   "source": [
    "!gcloud iam service-accounts keys create $CREDENTIALS_FILE \\\n",
    "    --iam-account=\"glinux@jchavezar-demo.iam.gserviceaccount.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2ad27ea-8552-40cb-88e1-0f4053837eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ARTIFACTS_DIRECTORY=\"artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d8c7af2-3284-4150-923e-c10c0658ed46",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m local_model\u001b[38;5;241m.\u001b[39mdeploy_to_local_endpoint(\n\u001b[1;32m      2\u001b[0m     artifact_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_ARTIFACTS_DIRECTORY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m local_endpoint:\n\u001b[1;32m      4\u001b[0m     health_check_response \u001b[38;5;241m=\u001b[39m local_endpoint\u001b[38;5;241m.\u001b[39mrun_health_check()\n\u001b[1;32m      6\u001b[0m     predict_response \u001b[38;5;241m=\u001b[39m local_endpoint\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m      7\u001b[0m         request_file\u001b[38;5;241m=\u001b[39mINPUT_FILE,\n\u001b[1;32m      8\u001b[0m         headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      9\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/prediction/local_endpoint.py:193\u001b[0m, in \u001b[0;36mLocalEndpoint.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"Enters the runtime context related to this object.\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    195\u001b[0m     _logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException during entering a context: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/prediction/local_endpoint.py:276\u001b[0m, in \u001b[0;36mLocalEndpoint.serve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_is_running \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# Waits until the model server starts.\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_until_health_check_succeeds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    278\u001b[0m     _logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException during starting serving: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/prediction/local_endpoint.py:320\u001b[0m, in \u001b[0;36mLocalEndpoint._wait_until_health_check_succeeds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m elapsed_time \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_ready_timeout \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    318\u001b[0m     response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m    319\u001b[0m ):\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainer_ready_check_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     elapsed_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_ready_check_interval\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=f\"{MODEL_ARTIFACTS_DIRECTORY}\",\n",
    ") as local_endpoint:\n",
    "    health_check_response = local_endpoint.run_health_check()\n",
    "\n",
    "    predict_response = local_endpoint.predict(\n",
    "        request_file=INPUT_FILE,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a954f3c-e71e-45c9-9cfc-4bd537d477cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m local_model\u001b[38;5;241m.\u001b[39mdeploy_to_local_endpoint(\n\u001b[1;32m      2\u001b[0m     artifact_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://vtx-metadata/model/xgboost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     credential_path\u001b[38;5;241m=\u001b[39mCREDENTIALS_FILE,\n\u001b[1;32m      4\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m local_endpoint:\n\u001b[1;32m      5\u001b[0m     predict_response \u001b[38;5;241m=\u001b[39m local_endpoint\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m      6\u001b[0m         request_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc/input.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m         headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     health_check_response \u001b[38;5;241m=\u001b[39m local_endpoint\u001b[38;5;241m.\u001b[39mrun_health_check()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/prediction/local_endpoint.py:193\u001b[0m, in \u001b[0;36mLocalEndpoint.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"Enters the runtime context related to this object.\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    195\u001b[0m     _logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException during entering a context: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/prediction/local_endpoint.py:276\u001b[0m, in \u001b[0;36mLocalEndpoint.serve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_is_running \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# Waits until the model server starts.\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_until_health_check_succeeds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    278\u001b[0m     _logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException during starting serving: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/prediction/local_endpoint.py:320\u001b[0m, in \u001b[0;36mLocalEndpoint._wait_until_health_check_succeeds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m elapsed_time \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_ready_timeout \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    318\u001b[0m     response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m    319\u001b[0m ):\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainer_ready_check_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     elapsed_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_ready_check_interval\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=\"gs://vtx-metadata/model/xgboost\",\n",
    "    credential_path=CREDENTIALS_FILE,\n",
    ") as local_endpoint:\n",
    "    predict_response = local_endpoint.predict(\n",
    "        request_file=\"src/input.json\",\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "    \n",
    "    health_check_response = local_endpoint.run_health_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df6a90e6-f594-42f5-aa8d-62bdab9dfbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.prediction.local_endpoint:Got the project id from the global config: jchavezar-demo.\n",
      "INFO:google.cloud.aiplatform.docker_utils.run:Container already exited, all container logs:\n",
      "INFO:google.cloud.aiplatform.docker_utils.run:Traceback (most recent call last):\n",
      "INFO:google.cloud.aiplatform.docker_utils.run:  File \"src/entrypoint.py\", line 13, in <module>\n",
      "INFO:google.cloud.aiplatform.docker_utils.run:    model_server_class: Type[prediction.model_server.ModelServer] = prediction.model_server.ModelServer,\n",
      "INFO:google.cloud.aiplatform.docker_utils.run:AttributeError: module 'google.cloud.aiplatform.prediction' has no attribute 'model_server'\n",
      "ERROR:google.cloud.aiplatform.prediction.local_endpoint:Exception during starting serving: ('Container exited before the first health check succeeded.', '', 1).\n",
      "ERROR:google.cloud.aiplatform.prediction.local_endpoint:Exception during entering a context: ('Container exited before the first health check succeeded.', '', 1).\n"
     ]
    },
    {
     "ename": "DockerError",
     "evalue": "('Container exited before the first health check succeeded.', '', 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDockerError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_231050/2116176548.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m with local_model.deploy_to_local_endpoint(\n\u001b[1;32m      2\u001b[0m     \u001b[0martifact_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"gs://vtx-metadata/model/xgboost\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcredential_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCREDENTIALS_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m ) as local_endpoint:\n\u001b[1;32m      5\u001b[0m     predict_response = local_endpoint.predict(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/prediction/local_endpoint.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;34m\"\"\"Enters the runtime context related to this object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Exception during entering a context: {exception}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/prediction/local_endpoint.py\u001b[0m in \u001b[0;36mserve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer_is_running\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# Waits until the model server starts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_until_health_check_succeeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Exception during starting serving: {exception}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/prediction/local_endpoint.py\u001b[0m in \u001b[0;36m_wait_until_health_check_succeeds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    331\u001b[0m                 )\n\u001b[1;32m    332\u001b[0m                 raise DockerError(\n\u001b[0;32m--> 333\u001b[0;31m                     \u001b[0;34m\"Container exited before the first health check succeeded.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m                 )\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDockerError\u001b[0m: ('Container exited before the first health check succeeded.', '', 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "with local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=f\"gs://vtx-metadata/model/xgboost\",\n",
    "    credential_path=CREDENTIALS_FILE,\n",
    ") as local_endpoint:\n",
    "    predict_response = local_endpoint.predict(\n",
    "        request_file= \"src/input.json\",\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "    \n",
    "    health_check_response = local_endpoint.run_health_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb804bd0-394c-427f-8acc-d3a192000034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.json\tlocal_cpr.ipynb  src\n"
     ]
    }
   ],
   "source": [
    "!ls ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0b3ece8-9d2a-4a0b-bdd0-8e170f376e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jesusarguelles/code/vertex-gpu/cpr\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d861877-d03b-463b-bafc-e4e2e01113b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
